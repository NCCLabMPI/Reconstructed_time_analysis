---
title: "ReconTime analysis"
output: html_document
date: "2023-08-22"
---

# housekeeping

```{r huosekeeping}

# clear workspace
rm(list = ls())

# define workspace
wd = 'C:/Users/alexander.lepauvre/Documents/GitHub/Reconstructed_time_analysis'
setwd(wd)
bids_root = 'C:/Users/alexander.lepauvre/Documents/GitHub/Reconstructed_time_analysis/bids'
```

# required packages

```{r packages} 

# get package manager package
if (!('pacman' %in% installed.packages()))
{install.packages("pacman")}
library(pacman)

# install all needed packages 
pacman::p_load('dplyr', 'ggdist', 'ggeffects', 'ggpubr', 'lme4', 'emmeans', 'rstatix', 'car', 'rsq', 'sjPlot')

```

# details of subjects for experiment 1

```{r subjects1}

# vector of included subjects (experiment of subjects 104 was aborted because of technique issues, number 122 is missing because of error in subject number assignment [see below at experiment 2])
subNums = c(101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123)
n = length(subNums)
ses = 1
Lab_ID = 'SX'

# experiment 1 is refered to as 'prp' task
task = 'prp'

```

# loading files for experiment 1

```{r loading1}

# initialize variables for loop 
count = 0
sub_ids = NaN
table_size = 1:n

# loop through subject numbers and load data
for (subNum in subNums ){
count = count + 1
sub_ids[count] = paste0(Lab_ID, subNum)

# make file name
sub_folder = paste0('sub-', Lab_ID, subNum)
ses_folder = paste0('ses-', ses)
file_name = paste0(sub_folder, '_', ses_folder, '_run-all_task-', task,'_events.csv')

# make file directory
file = file.path(bids_root, sub_folder, ses_folder, 'beh', file_name)

# load file name 
event_table = read.csv(file)

# store table size
table_size[count] = dim(event_table)[1]
    
# make format consistent
if ('X' %in% colnames(event_table))
{event_table$X <- NULL}

colnames(event_table)[which(names(event_table) == "has_repsonse_vis")] <- "has_response_vis"
colnames(event_table)[which(names(event_table) == "trial_repsonse_vis")] <- "trial_response_vis"

# add subject number column 
event_table = event_table %>% mutate(sub_num = subNum)

# z-score of RT_vis and RTaud (for within subject z-scoring)
event_table = event_table %>% mutate(z_RT_vis = (RT_vis-mean(RT_vis, na.rm = TRUE))/sd(RT_vis, na.rm = TRUE))
event_table = event_table %>% mutate(z_RT_aud = (RT_aud-mean(RT_aud, na.rm = TRUE))/sd(RT_aud, na.rm = TRUE))

# concatenate the tables
if ( exists('all_event_table')){
  all_event_table = rbind(all_event_table, event_table)
} else {
  all_event_table = event_table
}
}

```

# apply trial exclusion

```{r trial_exclusion1}

# store table without trial exclusion
raw_event_table = all_event_table

# add response window column (time between tone and end of trial)
all_event_table = all_event_table %>% mutate(resp_window = (2-onset_SOA)+stim_jit )

# remove RTaud > mean response window for offset, long duration and long SOA (deviation from preregistration)
max_RT = mean(all_event_table$resp_window[all_event_table$SOA == 0.466 & all_event_table$SOA_lock == 'offset' & all_event_table$duration == 1.5], na.rm = TRUE)
all_event_table = all_event_table[all_event_table$RT_aud < max_RT, ]

# remove RTaud < 100 ms
all_event_table = all_event_table[all_event_table$RT_aud > 0.1, ]

# remove false alarm
all_event_table = all_event_table[all_event_table$trial_response_vis != 'fa', ]

# remove incorrect auditory responses
all_event_table = all_event_table[all_event_table$trial_accuracy_aud == 1, ]

# remove NaNs from auditory responses
all_event_table = all_event_table[!is.na(all_event_table$RT_aud), ]

# store table with targets
target_event_table = all_event_table

# remove target trials from all_event_table
all_event_table = all_event_table[all_event_table$task_relevance != 'target', ]

```

# transfrom data

``` {r transform_data1}

# make task relevance and SOA lock numeric
all_event_table = all_event_table %>% mutate(is_task_relevant = ifelse(task_relevance == 'non-target',1,0)) 
all_event_table = all_event_table %>% mutate(is_onset = ifelse(SOA_lock == 'onset',1,0))

# make SOA and duration oridnal factors 
all_event_table = all_event_table %>% mutate(f_SOA = factor(SOA, ordered = TRUE, levels = c("0", "0.116", "0.232", "0.466")))
all_event_table = all_event_table %>% mutate(f_duration = factor(duration, ordered = TRUE, levels = c("0.5", "1", "1.5")))

# center variables 
all_event_table = all_event_table %>% mutate(c_task_relevant = is_task_relevant - mean(is_task_relevant))
all_event_table = all_event_table %>% mutate(c_is_onset = is_onset - mean(is_onset))
all_event_table = all_event_table %>% mutate(c_SOA = SOA - mean(SOA))
all_event_table = all_event_table %>% mutate(c_duration = duration - mean(duration))
all_event_table = all_event_table %>% mutate(c_pitch = (pitch-1050)/100) # makes pitches 0.5 for high and -0.5 for low

```

# test exclusion criteria

```{R test_exclusion1}

# after trials removal
print('number of onset trials after trial removal (incl: targets)')
sum(target_event_table$SOA_lock == 'onset')
print('number of offset trials after trial removal (incl: targets)')
sum(target_event_table$SOA_lock == 'offset')

# before
print('number of onset trials before trial removal (incl: targets)')
sum(raw_event_table$SOA_lock == 'onset')
print('number of offset trials after trial removal (incl: targets)')
sum(raw_event_table$SOA_lock == 'offset')

# difference
print('number of onset trials removed (excl: targets)')
sum(raw_event_table$SOA_lock == 'onset' & raw_event_table$task_relevance != 'target') - sum(all_event_table$SOA_lock == 'onset')
print('number of offset trials removed (excl: targets)')
sum(raw_event_table$SOA_lock == 'offset' & raw_event_table$task_relevance != 'target') - sum(all_event_table$SOA_lock == 'offset')

# relative trial removal w/o targets
print('perceptage of onset trials removed (excl: targets)')
(sum(raw_event_table$SOA_lock == 'onset' & raw_event_table$task_relevance != 'target') - sum(all_event_table$SOA_lock == 'onset'))/sum(raw_event_table$SOA_lock == 'onset' & raw_event_table$task_relevance != 'target')

print('perceptage of offset trials removed (excl: targets)')
(sum(raw_event_table$SOA_lock == 'offset' & raw_event_table$task_relevance != 'target') - sum(all_event_table$SOA_lock == 'offset'))/sum(raw_event_table$SOA_lock == 'offset' & raw_event_table$task_relevance != 'target')


# relative trial removal targets
print('perceptage of onset target trials removed')
(sum(raw_event_table$SOA_lock == 'onset' & raw_event_table$task_relevance == 'target') - sum(target_event_table$SOA_lock == 'onset' & target_event_table$task_relevance == 'target'))/sum(raw_event_table$SOA_lock == 'onset' & raw_event_table$task_relevance == 'target')

print('perceptage of offset target trials removed')
(sum(raw_event_table$SOA_lock == 'offset' & raw_event_table$task_relevance == 'target') - sum(target_event_table$SOA_lock == 'offset' & target_event_table$task_relevance == 'target'))/sum(raw_event_table$SOA_lock == 'offset' & raw_event_table$task_relevance == 'target')

```

# performance experiment 1

``` {r perfromance1}

# initialize data frame with all columns needed 
perf = data.frame(matrix(ncol = 0, nrow = 1))
perf$sub_num = 'NaN'
perf$hits = NaN 
perf$misses = NaN
perf$crs = NaN # crs = correct rejects 
perf$fas = NaN # fas = false alarms
perf$hit_rate = NaN 
perf$fa_rate = NaN
perf$aud_acc = NaN
perf$RT_aud = NaN # RT after trial exclusion
perf$RT_vis = NaN
perf$RT_aud_raw = NaN # RT before trial exclusion
perf$RT_vis_raw = NaN
perf = perf[-c(1), ]

# loop through all subjects and get performance 
for (sub_num in subNums) {
  perf = perf %>% add_row(sub_num = as.character(sub_num),
                          hits = sum(raw_event_table$trial_response_vis =='hit' & raw_event_table$sub_num == sub_num),
                          misses = sum(raw_event_table$trial_response_vis =='miss' & raw_event_table$sub_num == sub_num),
                          crs = sum(raw_event_table$trial_response_vis =='cr' & raw_event_table$sub_num == sub_num),
                          fas = sum(raw_event_table$trial_response_vis =='fa' & raw_event_table$sub_num == sub_num),
                          hit_rate = hits/(hits+misses)*100,
                          fa_rate = fas/(fas+crs)*100,
                          aud_acc = mean(raw_event_table$trial_accuracy_aud[raw_event_table$sub_num == sub_num], na.rm = TRUE)*100,
                          RT_aud = mean(target_event_table$RT_aud[target_event_table$sub_num == sub_num], na.rm = TRUE)*1000,
                          RT_vis = mean(target_event_table$RT_vis[target_event_table$sub_num == sub_num], na.rm = TRUE)*1000,
                          RT_aud_raw = mean(raw_event_table$RT_aud[raw_event_table$sub_num == sub_num], na.rm = TRUE)*1000,
                          RT_vis_raw = mean(raw_event_table$RT_vis[raw_event_table$sub_num == sub_num], na.rm = TRUE)*1000)
}

# transfer hit rate and false alarm rate into visual accuracy 
perf = perf %>% mutate(vis_acc = (hits + crs)/(hits + misses + crs + fas)*100)

# add mean and SD
perf = perf %>% add_row(sub_num = 'mean',
                        hits = mean(perf$hits),
                        misses = mean(perf$misses),
                        crs = mean(perf$crs),
                        fas = mean(perf$fas),
                        hit_rate = mean(perf$hit_rate),
                        fa_rate = mean(perf$fa_rate),
                        aud_acc = mean(perf$aud_acc),
                        vis_acc = mean(perf$vis_acc),
                        RT_aud = mean(perf$RT_aud),
                        RT_vis = mean(perf$RT_vis),
                        RT_aud_raw = mean(perf$RT_aud_raw),
                        RT_vis_raw = mean(perf$RT_vis_raw))

perf = perf %>% add_row(sub_num = 'sd',
                        hits = sd(perf$hits[1:n]),
                        misses = sd(perf$misses[1:n]),
                        crs = sd(perf$crs[1:n]),
                        fas = sd(perf$fas[1:n]),
                        hit_rate = sd(perf$hit_rate[1:n]),
                        fa_rate = sd(perf$fa_rate[1:n]),
                        aud_acc = sd(perf$aud_acc[1:n]),
                        vis_acc = sd(perf$vis_acc[1:n]),
                        RT_aud = sd(perf$RT_aud[1:n]),
                        RT_vis = sd(perf$RT_vis[1:n]),
                        RT_aud_raw = sd(perf$RT_aud_raw[1:n]),
                        RT_vis_raw = sd(perf$RT_vis_raw[1:n]))

```


# main analysis experiment - model 1 

Generalized linear mixed effect model (GLMM)

fixed effects: SOA (ordinal), SOA-Lock (as c_is_onset,  numeric, centered), Task-relevance (as is relevant, numeric, centered)
random effects: Subject ID, Duration (ordinal)

```{r glmm1_epx1}

# single trial level (as preregistered)

# fit model
model1 = glmer(RT_aud ~ f_SOA*c_is_onset*c_task_relevant +
                     (1*f_SOA*c_is_onset*c_task_relevant | sub_id)+
                     (1*f_SOA*c_is_onset*c_task_relevant | f_duration),
               family=Gamma(link="identity"), data=all_event_table)

summary(model1)

# get chisquare and p values 
Anova(model1)

# residual plots for visual inspection
plot(fitted(model1),residuals(model1))
qqnorm(residuals(model1))

# get R square
rsq.glmm(model1)


# subject level model (mean of each cell for each subjects - no single trials) (not preregistered)

subj_data = all_event_table %>% group_by(f_SOA, c_is_onset, c_task_relevant, sub_id, f_duration) %>%
                                      summarise(RT_mean = mean(RT_aud, na.rm = TRUE))

sub_model1 = glmer(RT_mean ~ f_SOA*c_is_onset*c_task_relevant +
                     (1*f_SOA*c_is_onset*c_task_relevant | sub_id)+
                     (1*f_SOA*c_is_onset*c_task_relevant | f_duration),
               family=Gamma(link="identity"), data = subj_data)

summary(sub_model1)

# get chisquare and p values 
Anova(sub_model1)

# get R square
rsq.glmm(sub_model1)
```

# onset PRP analysis
- as preregistered

```{r onset_PRP1}

# sub analysis restricted to onset

onset_event_table = all_event_table %>% filter(SOA_lock == "onset")

# fit onset model 
onset_model = glmer(RT_aud ~ f_SOA*c_task_relevant +
                       (1*f_SOA*c_task_relevant | sub_id) + 
                      (1*f_SOA*c_task_relevant | f_duration), 
                     family = Gamma(link="identity"), data = onset_event_table)

summary(onset_model)

# get chisquare and p values 
Anova(onset_model)

# get R square
rsq.glmm(onset_model)

```

# offset PRP analysis
- as preregistered

```{r offset_PRP1}

# sub analysis restricted to offset

offset_event_table = all_event_table %>% filter(SOA_lock == "offset")

# fit offset model
offset_model = glmer(RT_aud ~ f_SOA*f_duration*c_task_relevant +
                       (1*f_SOA*f_duration*c_task_relevant | sub_id), 
                     family = Gamma(link="identity"), data = offset_event_table)

summary(offset_model)

# get chisquare and p values 
Anova(offset_model)

# get R square
rsq.glmm(offset_model)


# post-hoc bonferroni corrected pairwise comparison

em1 <- emmeans(offset_model, "f_SOA", by = "f_duration")
contrast(em1, "pairwise", adjust = "bonferroni")

```

# control model
- as preregistered

```{r ctr_model1}


# with duration, category and pitch as random effects 

ctr_model = glmer(RT_aud ~ f_SOA*c_is_onset*c_task_relevant +
                     (1*f_SOA*c_is_onset*c_task_relevant | sub_id) +
                     (1*f_SOA*c_is_onset*c_task_relevant | f_duration) +
                     (1*f_SOA*c_is_onset*c_task_relevant | c_pitch) +
                     (1*f_SOA*c_is_onset*c_task_relevant | category), 
                   family=Gamma(link="identity"), data=all_event_table)


summary(ctr_model)

# get chisquare and p values 
Anova(ctr_model)

# get R square
rsq.glmm(ctr_model)

# compare control_model with main model
anova(model1, ctr_model)

```

# accuracy analysis - acc_model
GLMM with auditory accuracy as a dependent variable and SAO, onset/offset and task-relevance as fixed effects
- not preregistered

```{r acc_model}

# make task relevance and SOA lock numeric
acc_event_table = raw_event_table %>% mutate(is_task_relevant = ifelse(task_relevance == 'non-target',1,0)) 
acc_event_table = acc_event_table %>% mutate(is_onset = ifelse(SOA_lock == 'onset',1,0))

# make SOA and duration factors 
acc_event_table = acc_event_table %>% mutate(f_SOA = factor(SOA, ordered = TRUE, levels = c("0", "0.116", "0.232", "0.466")))
acc_event_table = acc_event_table %>% mutate(f_duration = factor(duration, ordered = TRUE, levels = c("0.5", "1", "1.5")))

# center variables 
acc_event_table = acc_event_table %>% mutate(c_task_relevant = is_task_relevant - mean(is_task_relevant))
acc_event_table = acc_event_table %>% mutate(c_is_onset = is_onset - mean(is_onset))
acc_event_table = acc_event_table %>% mutate(c_SOA = SOA - mean(SOA))
acc_event_table = acc_event_table %>% mutate(c_duration = duration - mean(duration))
# remove targets 
acc_event_table = acc_event_table %>% filter(task_relevance != 'target')

acc_model = glmer(trial_accuracy_aud ~ f_SOA*c_is_onset*c_task_relevant +
                     (1*f_SOA*c_is_onset*c_task_relevant | sub_id)+
                     (1*f_SOA*c_is_onset*c_task_relevant | f_duration),
              family = binomial, data=acc_event_table)

summary(acc_model)
Anova(acc_model)


```

# effect size of PRP

PRP effect magnitude: Difference in ms between short SOA and longest SOA for certain condition
PRP effect size: Cohen's D effect size for the same contrast

```{r effect_size1}

# initialize varibales
effect_size_table = matrix(ncol = 6, nrow = 5)
rownames(effect_size_table) = c("Mean_SOA0", "Mean_SOA466", "PRP_size", "joined_SD", "Cohensd")
colnames(effect_size_table) = c("target", "non_target_onset", "irrelevant_onset", "offset_short", "offset_intermediate", "offset_long")

# mean of SOA = 0
effect_size_table[1, ] = c(mean(target_event_table %>% filter(SOA == 0 & SOA_lock == 'onset' & task_relevance == 'target') %>% pull(RT_aud), na.rm = TRUE),
                           mean(target_event_table %>% filter(SOA == 0 & SOA_lock == 'onset' & task_relevance == 'non-target') %>% pull(RT_aud), na.rm = TRUE), 
                           mean(target_event_table %>% filter(SOA == 0 & SOA_lock == 'onset' & task_relevance == 'irrelevant') %>% pull(RT_aud), na.rm = TRUE), 
                           mean(all_event_table %>% filter(SOA == 0 & SOA_lock == 'offset' & duration == 0.5) %>% pull(RT_aud), na.rm = TRUE), 
                           mean(all_event_table %>% filter(SOA == 0 & SOA_lock == 'offset' & duration == 1) %>% pull(RT_aud), na.rm = TRUE), 
                           mean(all_event_table %>% filter(SOA == 0 & SOA_lock == 'offset' & duration == 1.5) %>% pull(RT_aud), na.rm = TRUE))

# mean of SOA = 466
effect_size_table[2, ] = c(mean(target_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' & task_relevance == 'target' & duration == 1.5) %>% pull(RT_aud), na.rm = TRUE),
                           mean(target_event_table %>% filter(SOA == 0.466 & SOA_lock == 'onset' & task_relevance == 'non-target') %>% pull(RT_aud), na.rm = TRUE),
                           mean(target_event_table %>% filter(SOA == 0.466 & SOA_lock == 'onset' & task_relevance == 'irrelevant') %>% pull(RT_aud), na.rm = TRUE),
                           mean(all_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' &  duration == 0.5) %>% pull(RT_aud), na.rm = TRUE),
                           mean(all_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' &  duration == 1) %>% pull(RT_aud), na.rm = TRUE),
                           mean(all_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' &  duration == 1.5) %>% pull(RT_aud), na.rm = TRUE))

# PRP size
effect_size_table[3, ] = effect_size_table[1, ] - effect_size_table[2, ] 

# joined SD
effect_size_table[4, ] = c(sd(c(target_event_table %>% filter(SOA == 0 & SOA_lock == 'onset' & task_relevance == 'target') %>% pull(RT_aud),target_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' & task_relevance == 'target' & duration == 1.5) %>% pull(RT_aud))),
                           sd(c(target_event_table %>% filter(SOA == 0 & SOA_lock == 'onset' & task_relevance == 'non-target') %>% pull(RT_aud), target_event_table %>% filter(SOA == 0.466 & SOA_lock == 'onset' & task_relevance == 'non-target') %>% pull(RT_aud))),
                           sd(c(target_event_table %>% filter(SOA == 0 & SOA_lock == 'onset' & task_relevance == 'irrelevant') %>% pull(RT_aud), target_event_table %>% filter(SOA == 0.466 & SOA_lock == 'onset' & task_relevance == 'irrelevant') %>% pull(RT_aud))),
                           sd(c(all_event_table %>% filter(SOA == 0 & SOA_lock == 'offset' & duration == 0.5) %>% pull(RT_aud), all_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' &  duration == 0.5) %>% pull(RT_aud))),
                           sd(c(all_event_table %>% filter(SOA == 0 & SOA_lock == 'offset' & duration == 1) %>% pull(RT_aud), all_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' &  duration == 1) %>% pull(RT_aud))),
                           sd(c(all_event_table %>% filter(SOA == 0 & SOA_lock == 'offset' & duration == 1.5) %>% pull(RT_aud), all_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' &  duration == 1.5) %>% pull(RT_aud))))

# cohens d 
effect_size_table[5, ] = (effect_size_table[1, ] - effect_size_table[2, ])/effect_size_table[4, ]

```

## ========================================================================== ##

# Experiment 2
As experiment 1 but with introspective ratings of decision time for both tasks (called iRT_aud and iRT_vis)

# loading files for experiment 2

```{r loading2}

# details of subjects  
subNums2 = c(105, 106, 108, 109, 110, 113, 114, 115, 116, 118) # 101 excluded, 122 is the same as participant 116 from experiment one
n2 = length(subNums2)
sessions2 = c(2,3)
Lab_ID = 'SX'

# experiment 2 will be refered to as task 'introspection'
task = 'introspection'

# initialize loop variables
count = 0
sub_ids = NaN
table_size = 1:n2*2

# loading the files 

# loop through subject and session numbers
for (subNum in subNums2){
  for (ses in sessions2){
    
    count = count + 1
    sub_ids[count] = paste0(Lab_ID, subNum)
    
    # make folder and file name
    sub_folder = paste0('sub-', Lab_ID, subNum)
    ses_folder = paste0('ses-', ses)
    file_name = paste0(sub_folder, '_', ses_folder, '_run-all_task-', task,'_events.csv')
    
    # make file directory 
    file = file.path(bids_root, sub_folder, ses_folder, 'beh', file_name)
    
    # load file
    event_table2 = read.csv(file)
     
    # store table dimensions
    table_size[count] = dim(event_table2 %>% filter(task_relevance != 'target'))[1]
       
    # make format consistent
    if ('X' %in% colnames(event_table2))
    {event_table2$X <- NULL}
    
    colnames(event_table2)[which(names(event_table2) == "has_repsonse_vis")] <- "has_response_vis"
    colnames(event_table2)[which(names(event_table2) == "trial_repsonse_vis")] <- "trial_response_vis"
    
    # add subject number and session column 
    event_table2 = event_table2 %>% mutate(sub_num = subNum)
    event_table2 = event_table2 %>% mutate(ses = ses)
    
    # z-score of iRT_vis and iRT_aud
    event_table2 = event_table2 %>% mutate(z_iRT_vis = (iRT_vis-mean(iRT_vis))/sd(iRT_vis))
    event_table2 = event_table2 %>% mutate(z_iRT_aud = (iRT_aud-mean(iRT_aud))/sd(iRT_aud))
    
    # z-score of RT_vis and RTaud
    event_table2 = event_table2 %>% mutate(z_RT_vis = (RT_vis-mean(RT_vis, na.rm = TRUE))/sd(RT_vis, na.rm = TRUE))
    event_table2 = event_table2 %>% mutate(z_RT_aud = (RT_aud-mean(RT_aud, na.rm = TRUE))/sd(RT_aud, na.rm = TRUE))
    
    # concatenate the tables
    if ( exists('all_event_table2')){
      all_event_table2 = rbind(all_event_table2, event_table2)
    } else {
      all_event_table2 = event_table2
    }
  }}

# 116 and 122 are the same person - should have the same id
all_event_table2 = all_event_table2 %>% mutate(sub_num = ifelse(sub_num == 122, 116, sub_num))
all_event_table2 = all_event_table2 %>% mutate(sub_id = ifelse(sub_id == 'SX122','SX116', sub_id))

```

# apply trial exclusion for experiment 2

```{r trial_exclusion2}

# store table without exclusion
raw_event_table2 = all_event_table2

# # remove false alarms
all_event_table2 = all_event_table2[all_event_table2$trial_response_vis != 'fa', ]

# make iRT of 0 a 1 (zeros cause errors in GLMM with gamma family)
all_event_table2$iRT_vis[all_event_table2$iRT_vis == 0] = 1
all_event_table2$iRT_aud[all_event_table2$iRT_aud == 0] = 1

# # remove RT < 100 ms
all_event_table2 = all_event_table2[all_event_table2$RT_aud > 0.1, ]

# add response window column
all_event_table2 = all_event_table2 %>% mutate(resp_window = (2-onset_SOA)+stim_jit )

# remove RTaud > mean response window for offset, long duration and long SOA (deviation from preregistration)
max_RT = mean(all_event_table2$resp_window[all_event_table2$SOA == 0.466 & all_event_table2$SOA_lock == 'offset' & all_event_table2$duration == 1.5], na.rm = TRUE)
all_event_table2 = all_event_table2[all_event_table2$RT_aud < max_RT, ]

# remove incorrect auditory responses
all_event_table2 = all_event_table2[all_event_table2$trial_accuracy_aud == 1, ]

# remove NaNs from auditory responses
all_event_table2 = all_event_table2[!is.na(all_event_table2$RT_aud), ]

# store table with targets
 target_event_table2 = all_event_table2

# remove target trials from all_event_table
all_event_table2 = all_event_table2[all_event_table2$task_relevance != 'target', ]

```

# transfrom data for experiment 2

``` {r transform_data2}

# add log transformed column
all_event_table2 = all_event_table2 %>% mutate(log_RT_aud = log(RT_aud))

# make task relevance and SOA lock numeric
all_event_table2 = all_event_table2 %>% mutate(is_task_relevant = ifelse(task_relevance == 'non-target',1,0)) 
all_event_table2 = all_event_table2 %>% mutate(is_onset = ifelse(SOA_lock == 'onset',1,0))

# make SOA and duration factors 
all_event_table2 = all_event_table2 %>% mutate(f_SOA = factor(SOA, ordered = TRUE, levels = c("0", "0.232", "0.466")))
all_event_table2 = all_event_table2 %>% mutate(f_duration = factor(duration, ordered = TRUE, levels = c("0.5", "1", "1.5")))

# center variables 
all_event_table2 = all_event_table2 %>% mutate(c_task_relevant = is_task_relevant - mean(is_task_relevant))
all_event_table2 = all_event_table2 %>% mutate(c_is_onset = is_onset - mean(is_onset))
all_event_table2 = all_event_table2 %>% mutate(c_SOA = SOA - mean(SOA))
all_event_table2 = all_event_table2 %>% mutate(c_duration = duration - mean(duration))
all_event_table2 = all_event_table2 %>% mutate(c_iRT_vis = (iRT_vis - mean(iRT_vis))/1000)
all_event_table2 = all_event_table2 %>% mutate(c_pitch = (pitch-1050)/100) # makes pitches 0.5 for high and -0.5 for low

```

# test exclusion criteria for experiment 2

```{R test exclusion2}

# after trials removal
print('number of onset trials after trial removal (incl: targets)')
sum(target_event_table2$SOA_lock == 'onset')
print('number of offset trials after trial removal (incl: targets)')
sum(target_event_table2$SOA_lock == 'offset')

# before
print('number of onset trials before trial removal (incl: targets)')
sum(raw_event_table2$SOA_lock == 'onset')
print('number of offset trials after trial removal (incl: targets)')
sum(raw_event_table2$SOA_lock == 'offset')

# difference
print('number of onset trials removed (excl: targets)')
sum(raw_event_table2$SOA_lock == 'onset' & raw_event_table2$task_relevance != 'target') - sum(all_event_table2$SOA_lock == 'onset')
print('number of offset trials removed (excl: targets)')
sum(raw_event_table2$SOA_lock == 'offset' & raw_event_table2$task_relevance != 'target') - sum(all_event_table2$SOA_lock == 'offset')

# relative trial removal w/o targets
print('perceptage of onset trials removed (excl: targets)')
(sum(raw_event_table2$SOA_lock == 'onset' & raw_event_table2$task_relevance != 'target') - sum(all_event_table2$SOA_lock == 'onset'))/sum(raw_event_table2$SOA_lock == 'onset' & raw_event_table2$task_relevance != 'target')

print('perceptage of offset trials removed (excl: targets)')
(sum(raw_event_table2$SOA_lock == 'offset' & raw_event_table2$task_relevance != 'target') - sum(all_event_table2$SOA_lock == 'offset'))/sum(raw_event_table2$SOA_lock == 'offset' & raw_event_table2$task_relevance != 'target')

# relative trial removal targets
print('perceptage of onset target trials removed')
(sum(raw_event_table2$SOA_lock == 'onset' & raw_event_table2$task_relevance == 'target') - sum(target_event_table2$SOA_lock == 'onset' & target_event_table2$task_relevance == 'target'))/sum(raw_event_table2$SOA_lock == 'onset' & raw_event_table2$task_relevance == 'target')

print('perceptage of offset target trials removed')
(sum(raw_event_table2$SOA_lock == 'offset' & raw_event_table2$task_relevance == 'target') - sum(target_event_table2$SOA_lock == 'offset' & target_event_table2$task_relevance == 'target'))/sum(raw_event_table2$SOA_lock == 'offset' & raw_event_table2$task_relevance == 'target')

```

# performance experiment 2

``` {r perfromance2}
perf2 = data.frame(matrix(ncol = 0, nrow = 1))
perf2$sub_num = 'NaN'
perf2$hits = NaN
perf2$misses = NaN
perf2$crs = NaN 
perf2$fas = NaN
perf2$hit_rate = NaN 
perf2$fa_rate = NaN
perf2$aud_acc = NaN
perf2$RT_aud = NaN
perf2$RT_vis = NaN
perf2$RT_aud_raw = NaN
perf2$RT_vis_raw = NaN
perf2 = perf2[-c(1), ]

for (sub_num in subNums) {
  perf2 = perf2 %>% add_row(sub_num = as.character(sub_num),
                          hits = sum(raw_event_table2$trial_response_vis =='hit' & raw_event_table2$sub_num == sub_num),
                          misses = sum(raw_event_table2$trial_response_vis =='miss' & raw_event_table2$sub_num == sub_num),
                          crs = sum(raw_event_table2$trial_response_vis =='cr' & raw_event_table2$sub_num == sub_num),
                          fas = sum(raw_event_table2$trial_response_vis =='fa' & raw_event_table2$sub_num == sub_num),
                          hit_rate = hits/(hits+misses)*100,
                          fa_rate = fas/(fas+crs)*100,
                          aud_acc = mean(raw_event_table2$trial_accuracy_aud[raw_event_table2$sub_num == sub_num], na.rm = TRUE)*100,
                          RT_aud = mean(target_event_table2$RT_aud[target_event_table2$sub_num == sub_num], na.rm = TRUE)*1000,
                          RT_vis = mean(target_event_table2$RT_vis[target_event_table2$sub_num == sub_num], na.rm = TRUE)*1000,
                          RT_aud_raw = mean(raw_event_table2$RT_aud[raw_event_table2$sub_num == sub_num], na.rm = TRUE)*1000,
                          RT_vis_raw = mean(raw_event_table2$RT_vis[raw_event_table2$sub_num == sub_num], na.rm = TRUE)*1000)
}

# transfer hit rate and false alarm rate into accuracy 
perf2 = perf2 %>% mutate(vis_acc = (hits + crs)/(hits + misses + crs + fas)*100)

# add mean and SD
perf2 = perf2 %>% add_row(sub_num = 'mean',
                        hits = mean(perf2$hits),
                        misses = mean(perf2$misses),
                        crs = mean(perf2$crs),
                        fas = mean(perf2$fas),
                        hit_rate = mean(perf2$hit_rate),
                        fa_rate = mean(perf2$fa_rate),
                        aud_acc = mean(perf2$aud_acc),
                        vis_acc = mean(perf2$vis_acc),
                        RT_aud = mean(perf2$RT_aud),
                        RT_vis = mean(perf2$RT_vis),
                        RT_aud_raw = mean(perf2$RT_aud_raw),
                        RT_vis_raw = mean(perf2$RT_vis_raw))

perf2 = perf2 %>% add_row(sub_num = 'sd',
                        hits = sd(perf2$hits[1:n2]),
                        misses = sd(perf2$misses[1:n2]),
                        crs = sd(perf2$crs[1:n2]),
                        fas = sd(perf2$fas[1:n2]),
                        hit_rate = sd(perf2$hit_rate[1:n2]),
                        fa_rate = sd(perf2$fa_rate[1:n2]),
                        aud_acc = sd(perf2$aud_acc[1:n2]),
                        vis_acc = sd(perf2$vis_acc[1:n2]),
                        RT_aud = sd(perf2$RT_aud[1:n2]),
                        RT_vis = sd(perf2$RT_vis[1:n2]),
                        RT_aud_raw = sd(perf2$RT_aud_raw[1:n2]),
                        RT_vis_raw = sd(perf2$RT_vis_raw[1:n2]))

# percentage of underestimation in RTaud
underest_RTaud = mean(all_event_table2$iRT_aud)/mean(all_event_table2$RT_aud*1000)

```


# main analysis - experiment 2
general linear mixed effect model 1 with iRTvis or iRT_aud as dependent variables - as preregistred

fixed effects: SOA (ordinal), SOA-Lock (as c_is_onset,  numeric, centered), Task-relevance (as c_task_relevant, numeric, centered)
random effects: Subject ID, Duration (ordinal)

```{r iRT_models}

#### Log instead of identity function #####

# auditory 
aud_iRT_model = glmer(iRT_aud ~ f_SOA*c_is_onset*c_task_relevant +
                     (1*f_SOA*c_is_onset*c_task_relevant | sub_id)+
                     (1*f_SOA*c_is_onset*c_task_relevant | f_duration),
                   family=Gamma(link="log"), data=all_event_table2)

summary(aud_iRT_model)

# get chisquare and p values 
Anova(aud_iRT_model)

# residual plots for visual inspection
plot(fitted(aud_iRT_model),residuals(aud_iRT_model))
qqnorm(residuals(aud_iRT_model))

# get R square
rsq.glmm(aud_iRT_model)

#### Log instead of identity function #####

# visual

vis_iRT_model = glmer(iRT_vis ~ f_SOA*c_is_onset*c_task_relevant +
                     (1*f_SOA*c_is_onset*c_task_relevant | sub_id)+
                     (1*f_SOA*c_is_onset*c_task_relevant | f_duration),
                   family=Gamma(link="log"), data=all_event_table2)

summary(vis_iRT_model)

# get chisquare and p values 
Anova(vis_iRT_model)

# residual plots for visual inspection
plot(fitted(vis_iRT_model),residuals(vis_iRT_model))
qqnorm(residuals(vis_iRT_model))

# get R square
rsq.glmm(vis_iRT_model )
```

# main analyses from experiment 1 
GLMMs as in section "glmm1_epx1", "onset_PRP1", and "offset_PRP1" but with data from second experiment

fixed effects: SOA (ordinal), SOA-Lock (as c_is_onset,  numeric, centered), Task-relevance (as is relevant, numeric, centered)
random effects: Subject ID, Duration (ordinal)

```{r model_from_exp1}

model_exp2 = glmer(RT_aud ~ f_SOA*c_is_onset*c_task_relevant +
                     (1*f_SOA*c_is_onset*c_task_relevant | sub_id)+
                     (1*f_SOA*c_is_onset*c_task_relevant | f_duration),
               family=Gamma(link="identity"), data=all_event_table2)

summary(model_exp2)

# get chisquare and p values 
Anova(model_exp2)

# get R square
rsq.glmm(model_exp2)


# onset PRP analysis
onset_event_table2 = all_event_table2 %>% filter(SOA_lock == "onset")

# new model (needs to be adjusted probably)

onset_model2 = glmer(RT_aud ~ f_SOA*c_task_relevant +
                       (1*f_SOA*c_task_relevant | sub_id) + 
                      (1*f_SOA*c_task_relevant | f_duration), 
                     family = Gamma(link="identity"), data = onset_event_table2)

summary(onset_model2)

# get chisquare and p values 
Anova(onset_model2)

# get R square
rsq.glmm(onset_model2)


# offset PRP analysis
offset_event_table2 = all_event_table2 %>% filter(SOA_lock == "offset")

# new model (needs to be adjusted probably)

offset_model2 = glmer(RT_aud ~ f_SOA*f_duration*c_task_relevant +
                       (1*f_SOA*f_duration*c_task_relevant | sub_id), 
                     family = Gamma(link="identity"), data = offset_event_table2)

summary(offset_model2)

# get chisquare and p values 
Anova(offset_model2)

# get R square
rsq.glmm(offset_model2)


# post hoc pairwise comparisons using bonferroni corrected t-testing 
em2 <- emmeans(offset_model, "f_SOA", by = "f_duration")
contrast(em2, "pairwise", adjust = "bonferroni")

```

# Relationship between T1 (iRTvis) and T2 (RTaud)

How much variance of T2 is explained by T1. How is this affected by SOA
- as preregistered

Correlation analysis and GLMM
- not preregistered

```{r iRTvis~RTaud}

# correlation analysis (showing correlation for different condition)
correlation_plot = ggplot(all_event_table2, aes(x = z_iRT_vis, y = RT_aud*1000, color = f_SOA)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(group = f_SOA)) +
  xlab("Visual introspective decision time [ms]") +
  ylab("Objective auditory reaction time [ms]") +
  scale_color_manual(values = c("#4775d1", '#ffbf00', "#666666"), name = "SOA [ms]", labels = c("0", "232", "466")) +
  facet_grid(duration ~ SOA_lock)+
  theme_bw() +
  theme(axis.line = element_line(colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(linetype = "solid"),
        panel.background = element_blank())+
  stat_cor(color = 'black', label.y = 3000, method = "pearson", show.legend = FALSE)+
  stat_cor(aes(color = f_SOA),label.y = c(2850,2700,2550), method = "pearson", show.legend = FALSE)
correlation_plot

# GLMM with iRTVis as predictor for RTaud
all_event_table2 = all_event_table2 %>% mutate(iRT_vis_0.001 = iRT_vis*0.001)

model_T1 = glmer(RT_aud ~ f_SOA*c_is_onset*c_task_relevant*iRT_vis_0.001 +
                   (1*f_SOA*c_is_onset*c_task_relevant*iRT_vis_0.001| sub_id)+
                   (1*f_SOA*c_is_onset*c_task_relevant*iRT_vis_0.001 | f_duration),
                 family=Gamma(link="identity"), data=all_event_table2)

summary(model_T1)
Anova(model_T1)
plot(fitted(model_T1),residuals(model_T1))
qqnorm(residuals(model_T1))
rsq.glmm(model_T1)

```


# Relationship between introspective and objective RT
In our data, we observe that despite the SOA effect on the iT being significant, the iT curve are much flatter than the RT curves, indicating that participants strongly underestimate their RT. Nonetheless, the iT is correlated with RT on a trial by trial basis. To quantify this two aspects of our data statistically, we compute Beta weights for the within and between SOA condition correlation of RT and iT. For that purpose, we compute two regressors: the mean RT per SOA condition and the deviation from mean RT on a trial by trial basis. We expect the mean RT per SOA to not explain a lot of variance, as the slope between mean RT and iT do not show a close association. On the other hand, participants iT still show a close association with RT overall, which should be reflected in a stronger correlation with the trial by trial deviation from the mean.

```{r RTaud~iRTaud}
# Subselect the column of interest:
df <- all_event_table2[, c("sub_id", "onset_SOA", "RT_aud", "iRT_aud")]

# Convert iRT to sec:
df <- df %>% mutate(iRT_aud_0.001 = iRT_aud*0.001)
# Log transform the RT:
df$RT_aud <- log(df$RT_aud)

# Compute mean RT audio separately for each SOA:
df <- df %>%
  group_by(onset_SOA) %>%
  mutate(mean_RT_aud = mean(RT_aud))
# Compute deviation between mean RT and single  trials RT:
df <- df %>%
  mutate(dev_RT_aud = RT_aud - mean_RT_aud)
# Mean center both predictors:
df$mean_RT_aud <- df$mean_RT_aud - mean(df$mean_RT_aud)
df$dev_RT_aud <- df$dev_RT_aud - mean(df$dev_RT_aud)

# Model iT as a function of mean RT and deviation from mean RT:
model_full = glmer(iRT_aud_0.001 ~ dev_RT_aud + mean_RT_aud +
                  (1 + dev_RT_aud + mean_RT_aud | sub_id), family=Gamma(link="log"), data=df)
model_meanRT = glmer(iRT_aud_0.001 ~ mean_RT_aud +
                  (1 + mean_RT_aud | sub_id), family=Gamma(link="log"), data=df)
model_devRT = glmer(iRT_aud_0.001 ~ dev_RT_aud +
                  (1 + dev_RT_aud | sub_id), family=Gamma(link="log"), data=df)

# Compute the proportion of variance explained by the mean and RT deviance respectively:
rsq_full <- rsq.glmm(model_full)
rsq_meanRT <- rsq.glmm(model_meanRT)
rsq_devRT <- rsq.glmm(model_devRT)
print('Variance explained by meanRT:')
print(rsq_full[['model']] - rsq_devRT[['model']])
print('Variance explained by devRT:')
print(rsq_full[['model']] - rsq_meanRT[['model']])

summary(model_full)
Anova(model_full)
plot(fitted(model_full),residuals(model_full))
qqnorm(residuals(model_full))

```

# power analysis
Based on Marti el al. (2010). What is the minimum sample size required to find a PRP effect that is 4 times smaller than what Mart et al. have found with a power of 0.8?

```{r power_analysis}
if (!('pwr' %in% installed.packages()))
{install.packages("pwr")}
library(pwr)

# from marti paper
f =  47.08
n = 10
df_num = 5
df_denom = 45

# effect size 
eta = (f * df_num ) / (f * df_num  + df_denom )
effect_size = sqrt((df_denom/n)*(eta/(1-eta)))

# Specify  desired power, and significance level
power = 0.80
alpha = 0.05

# degrees of freedom for the numerator for our analysis 
u = 1

# Estimate sample size for GLMM with logistic regression
v = pwr.f2.test(u = u, v = , f2 = effect_size/4, sig.level = .05, power = power)$v
  
# (v = n - u - 1\). This implies \(n = v + u + 1\).
req_sample_size = ceiling(v + u + 1)

# show result
print(paste0("The required sample size is: ", req_sample_size))

```
