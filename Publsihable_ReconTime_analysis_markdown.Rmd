---
title: "ReconTime analysis"
output: html_document
date: "2023-08-22"
---

# housekeeping

```{r huosekeeping}

# clear workspace
rm(list = ls())

# define workspace
wd = 'C:/Users/micha.engeser/Documents/GitHub/Reconstructed_time_analysis'
setwd(wd)
dir()
```

# required packages

```{r packages} 

# get package manager package
if (!('pacman' %in% installed.packages()))
{install.packages("pacman")}
library(pacman)

# install all needed packages 
pacman::p_load('dplyr', 'ggdist', 'ggeffects', 'ggpubr', 'lme4', 'emmeans', 'rstatix', 'car', 'rsq', 'sjPlot')

```

# details of subjects for experiment 1

```{r subjects1}

# vector of included subjects (experiment of subjects 104 was aborted because of technique issues, number 122 is missing because of error in subject number assignment [see below at experiment 2])
subNums = c(101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123)
n = length(subNums)
ses = 1
Lab_ID = 'SX'

# experiment 1 is refered to as 'prp' task
task = 'prp'

```

# loading files for experiment 1

```{r loading1}

# initialize variables for loop 
count = 0
sub_ids = NaN
table_size = 1:n

# loop through subject numbers and load data
for (subNum in subNums ){
count = count + 1
sub_ids[count] = paste0(Lab_ID, subNum)

# make file name
sub_folder = paste0('sub-', Lab_ID, subNum)
ses_folder = paste0('ses-', ses)
file_name = paste0(sub_folder, '_', ses_folder, '_run-all_task-', task,'_events.csv')

# make file directory
setwd("..")
parent_dir = getwd()
setwd(wd)
file = file.path(parent_dir, 'Reconstructed_time_experiment', 'data', sub_folder, ses_folder, file_name)

# load file name 
event_table = read.csv(file)

# store table size
table_size[count] = dim(event_table)[1]
    
# make format consistent
if ('X' %in% colnames(event_table))
{event_table$X <- NULL}

colnames(event_table)[which(names(event_table) == "has_repsonse_vis")] <- "has_response_vis"
colnames(event_table)[which(names(event_table) == "trial_repsonse_vis")] <- "trial_response_vis"

# add subject number column 
event_table = event_table %>% mutate(sub_num = subNum)

# z-score of RT_vis and RTaud (for within subject z-scoring)
event_table = event_table %>% mutate(z_RT_vis = (RT_vis-mean(RT_vis, na.rm = TRUE))/sd(RT_vis, na.rm = TRUE))
event_table = event_table %>% mutate(z_RT_aud = (RT_aud-mean(RT_aud, na.rm = TRUE))/sd(RT_aud, na.rm = TRUE))

# concatenate the tables
if ( exists('all_event_table')){
  all_event_table = rbind(all_event_table, event_table)
} else {
  all_event_table = event_table
}
}

```

# apply trial exclusion

```{r trial_exclusion1}

# store table without trial exclusion
raw_event_table = all_event_table

# add response window column (time between tone and end of trial)
all_event_table = all_event_table %>% mutate(resp_window = (2-onset_SOA)+stim_jit )

# remove RTaud > mean response window for offset, long duration and long SOA (deviation from preregistration)
max_RT = mean(all_event_table$resp_window[all_event_table$SOA == 0.466 & all_event_table$SOA_lock == 'offset' & all_event_table$duration == 1.5], na.rm = TRUE)
all_event_table = all_event_table[all_event_table$RT_aud < 1.8, ]

# remove RTaud < 100 ms
all_event_table = all_event_table[all_event_table$RT_aud > 0.1, ]

# remove false alarm
all_event_table = all_event_table[all_event_table$trial_response_vis != 'fa', ]

# remove incorrect auditory responses
all_event_table = all_event_table[all_event_table$trial_accuracy_aud == 1, ]

# remove NaNs from auditory responses
all_event_table = all_event_table[!is.na(all_event_table$RT_aud), ]

# store table with targets
target_event_table = all_event_table

# remove target trials from all_event_table
all_event_table = all_event_table[all_event_table$task_relevance != 'target', ]

# check if any combination of core conditions (cell) has less than 30 trials 
task_relevance_lvl = c('non-target', 'irrelevant')
SOA_lock_lvl = c('onset', 'offset')
SOA_lvl = c(0,0.116,0.232,0.466)
duration_lvl = c(0.5,1,1.5)
sub_id_lvl = sub_ids


for (o in sub_id_lvl){
  for (i in SOA_lvl){
    for (ii in SOA_lock_lvl) {
      for (iii in task_relevance_lvl) {
        for (iv in duration_lvl) {
          
          cell_trials = sum(all_event_table$sub_id == o & all_event_table$SOA == i & all_event_table$SOA_lock == ii & all_event_table$task_relevance == iii & all_event_table$duration == iv, na.rm = TRUE)
          

          if(cell_trials < 30){
            cell_name = paste(i,ii,iii,iv,sep= '-')
            warning(paste0('Subject ',o,' has only ', cell_trials,' trials for cell: ', cell_name, '\n'))
          }
        }}}}}

```

# transfrom data

``` {r transform_data1}

# make task relevance and SOA lock numeric
all_event_table = all_event_table %>% mutate(is_task_relevant = ifelse(task_relevance == 'non-target',1,0)) 
all_event_table = all_event_table %>% mutate(is_onset = ifelse(SOA_lock == 'onset',1,0))

# make SOA and duration oridnal factors 
all_event_table = all_event_table %>% mutate(f_SOA = factor(SOA, ordered = TRUE, levels = c("0", "0.116", "0.232", "0.466")))
all_event_table = all_event_table %>% mutate(f_duration = factor(duration, ordered = TRUE, levels = c("0.5", "1", "1.5")))

# center variables 
all_event_table = all_event_table %>% mutate(c_task_relevant = is_task_relevant - mean(is_task_relevant))
all_event_table = all_event_table %>% mutate(c_is_onset = is_onset - mean(is_onset))
all_event_table = all_event_table %>% mutate(c_SOA = SOA - mean(SOA))
all_event_table = all_event_table %>% mutate(c_duration = duration - mean(duration))
all_event_table = all_event_table %>% mutate(c_pitch = (pitch-1050)/100) # makes pitches 0.5 for high and -0.5 for low

```

# test exclusion criteria

```{R test_exclusion1}

# after trials removal
print('number of onset trials after trial removal (incl: targets)')
sum(target_event_table$SOA_lock == 'onset')
print('number of offset trials after trial removal (incl: targets)')
sum(target_event_table$SOA_lock == 'offset')

# before
print('number of onset trials before trial removal (incl: targets)')
sum(raw_event_table$SOA_lock == 'onset')
print('number of offset trials after trial removal (incl: targets)')
sum(raw_event_table$SOA_lock == 'offset')

# difference
print('number of onset trials removed (excl: targets)')
sum(raw_event_table$SOA_lock == 'onset' & raw_event_table$task_relevance != 'target') - sum(all_event_table$SOA_lock == 'onset')
print('number of offset trials removed (excl: targets)')
sum(raw_event_table$SOA_lock == 'offset' & raw_event_table$task_relevance != 'target') - sum(all_event_table$SOA_lock == 'offset')

# relative trial removal w/o targets
print('perceptage of onset trials removed (excl: targets)')
(sum(raw_event_table$SOA_lock == 'onset' & raw_event_table$task_relevance != 'target') - sum(all_event_table$SOA_lock == 'onset'))/sum(raw_event_table$SOA_lock == 'onset' & raw_event_table$task_relevance != 'target')

print('perceptage of offset trials removed (excl: targets)')
(sum(raw_event_table$SOA_lock == 'offset' & raw_event_table$task_relevance != 'target') - sum(all_event_table$SOA_lock == 'offset'))/sum(raw_event_table$SOA_lock == 'offset' & raw_event_table$task_relevance != 'target')


# relative trial removal targets
print('perceptage of onset target trials removed')
(sum(raw_event_table$SOA_lock == 'onset' & raw_event_table$task_relevance == 'target') - sum(target_event_table$SOA_lock == 'onset' & target_event_table$task_relevance == 'target'))/sum(raw_event_table$SOA_lock == 'onset' & raw_event_table$task_relevance == 'target')

print('perceptage of offset target trials removed')
(sum(raw_event_table$SOA_lock == 'offset' & raw_event_table$task_relevance == 'target') - sum(target_event_table$SOA_lock == 'offset' & target_event_table$task_relevance == 'target'))/sum(raw_event_table$SOA_lock == 'offset' & raw_event_table$task_relevance == 'target')

```

# performance experiment 1

``` {r perfromance1}

# initialize data frame with all columns needed 
perf = data.frame(matrix(ncol = 0, nrow = 1))
perf$sub_num = 'NaN'
perf$hits = NaN 
perf$misses = NaN
perf$crs = NaN # crs = correct rejects 
perf$fas = NaN # fas = false alarms
perf$hit_rate = NaN 
perf$fa_rate = NaN
perf$aud_acc = NaN
perf$RT_aud = NaN # RT after trial exclusion
perf$RT_vis = NaN
perf$RT_aud_raw = NaN # RT before trial exclusion
perf$RT_vis_raw = NaN
perf = perf[-c(1), ]

# loop through all subjects and get performance 
for (sub_num in subNums) {
  perf = perf %>% add_row(sub_num = as.character(sub_num),
                          hits = sum(raw_event_table$trial_response_vis =='hit' & raw_event_table$sub_num == sub_num),
                          misses = sum(raw_event_table$trial_response_vis =='miss' & raw_event_table$sub_num == sub_num),
                          crs = sum(raw_event_table$trial_response_vis =='cr' & raw_event_table$sub_num == sub_num),
                          fas = sum(raw_event_table$trial_response_vis =='fa' & raw_event_table$sub_num == sub_num),
                          hit_rate = hits/(hits+misses)*100,
                          fa_rate = fas/(fas+crs)*100,
                          aud_acc = mean(raw_event_table$trial_accuracy_aud[raw_event_table$sub_num == sub_num], na.rm = TRUE)*100,
                          RT_aud = mean(target_event_table$RT_aud[target_event_table$sub_num == sub_num], na.rm = TRUE)*1000,
                          RT_vis = mean(target_event_table$RT_vis[target_event_table$sub_num == sub_num], na.rm = TRUE)*1000,
                          RT_aud_raw = mean(raw_event_table$RT_aud[raw_event_table$sub_num == sub_num], na.rm = TRUE)*1000,
                          RT_vis_raw = mean(raw_event_table$RT_vis[raw_event_table$sub_num == sub_num], na.rm = TRUE)*1000)
}

# transfer hit rate and false alarm rate into visual accuracy 
perf = perf %>% mutate(vis_acc = (hits + crs)/(hits + misses + crs + fas)*100)

# add mean and SD
perf = perf %>% add_row(sub_num = 'mean',
                        hits = mean(perf$hits),
                        misses = mean(perf$misses),
                        crs = mean(perf$crs),
                        fas = mean(perf$fas),
                        hit_rate = mean(perf$hit_rate),
                        fa_rate = mean(perf$fa_rate),
                        aud_acc = mean(perf$aud_acc),
                        vis_acc = mean(perf$vis_acc),
                        RT_aud = mean(perf$RT_aud),
                        RT_vis = mean(perf$RT_vis),
                        RT_aud_raw = mean(perf$RT_aud_raw),
                        RT_vis_raw = mean(perf$RT_vis_raw))

perf = perf %>% add_row(sub_num = 'sd',
                        hits = sd(perf$hits[1:n]),
                        misses = sd(perf$misses[1:n]),
                        crs = sd(perf$crs[1:n]),
                        fas = sd(perf$fas[1:n]),
                        hit_rate = sd(perf$hit_rate[1:n]),
                        fa_rate = sd(perf$fa_rate[1:n]),
                        aud_acc = sd(perf$aud_acc[1:n]),
                        vis_acc = sd(perf$vis_acc[1:n]),
                        RT_aud = sd(perf$RT_aud[1:n]),
                        RT_vis = sd(perf$RT_vis[1:n]),
                        RT_aud_raw = sd(perf$RT_aud_raw[1:n]),
                        RT_vis_raw = sd(perf$RT_vis_raw[1:n]))

```


# plotting Figure 5a for experiment 1

```{R plotting_fig5a_exp1}

# define size of the plots

width = 1500
height = 1000


# RTaud and RTvis as a function of SOA from the visual stimulus onset, grouped by duration and subplots for task-relevance

# take mean RTauds for each condition and each subject
RTaud_table_fig5a = target_event_table %>% group_by(onset_SOA, SOA_lock, duration, sub_id, task_relevance) %>%
                                      summarise(RT_mean = mean(RT_aud, na.rm = TRUE)*1000)

# take mean and standard deviation of RTauds for each condition
RTaud_table_fig5a = RTaud_table_fig5a %>%  group_by(onset_SOA, SOA_lock,duration, task_relevance) %>%
                                      summarise(mean_RT = mean(RT_mean, na.rm = TRUE),
                                                         sd_RT = sd(RT_mean, na.rm = TRUE),
                                                         sem_RT = sd_RT / sqrt(n))

# take mean RTvis for each condition and each subject
RTvis_table_fig5a = target_event_table %>% group_by(onset_SOA,SOA_lock, sub_id, task_relevance, duration) %>%
                                      summarise(RT_mean_vis = mean(RT_vis, na.rm = TRUE)*1000)

# on onset collapse duration 
RTvis_table_fig5a= RTvis_table_fig5a %>% mutate(duration = ifelse(SOA_lock == 'onset',0,duration))

# take mean and standard deviation of RTvis for each condition
RTvis_table_fig5a = RTvis_table_fig5a %>%  group_by(onset_SOA, SOA_lock, task_relevance, duration) %>%
                                      summarise(mean_RT_vis = mean(RT_mean_vis, na.rm = TRUE),
                                                         sd_RT_vis = sd(RT_mean_vis, na.rm = TRUE),
                                                         sem_RT_vis = sd_RT_vis / sqrt(n))


# remove NaNs from auditory responses
RTaud_table_fig5a = RTaud_table_fig5a[!is.na(RTaud_table_fig5a$mean_RT), ]
RTvis_table_fig5a = RTvis_table_fig5a[!is.na(RTvis_table_fig5a$mean_RT_vis), ]

# define order of task-relevance
RTaud_table_fig5a$task_relevance = factor(RTaud_table_fig5a$task_relevance,
                                   levels = c('target', 'non-target', 'irrelevant'),
                                   labels = c('Target', 'Relevant non-target', 'Irrelevant non-target'))
RTvis_table_fig5a$task_relevance = factor(RTvis_table_fig5a$task_relevance,
                                   levels = c('target'),
                                   labels = c('Target'))

# start plotting
fig5a = ggplot(data = RTaud_table_fig5a, aes(x = onset_SOA*1000, y = mean_RT, group = interaction(as.character(duration), SOA_lock), color = as.character(duration), linetype = SOA_lock)) +
  # RTvis
  geom_line(data = RTvis_table_fig5a, aes(x = onset_SOA*1000, y = mean_RT_vis, color = 'darkgrey', group = interaction(as.character(duration), SOA_lock)), linewidth = 1) +
  geom_errorbar(data = RTvis_table_fig5a, aes(x = onset_SOA*1000, y = mean_RT_vis, ymin = (mean_RT_vis - sem_RT_vis), ymax = (mean_RT_vis + sem_RT_vis), group = interaction(as.character(duration), SOA_lock), color = 'darkgrey', width = 30), linewidth = 1) +
  geom_point(data = RTvis_table_fig5a, aes(x = onset_SOA*1000, y = mean_RT_vis, color = 'darkgrey', group = interaction(as.character(duration), SOA_lock)), size = 1.5) +
  # RTaud
  geom_line(linewidth = 1) +
  geom_errorbar(aes(ymin = (mean_RT - sem_RT), ymax = (mean_RT + sem_RT)), width = 30, linewidth = 1) +
  geom_point(size = 1.5) +
  # split by task-relevance
  facet_grid(. ~ task_relevance) +
  # define obtics 
  labs(title = "Objective reaction time by task-relevance", tag = "A") +
  ylab("Reaction time [ms]") +
  xlab('SOA to visual onset [ms]') +
  scale_color_manual(values = c('darkviolet', 'darkorange', 'darkred', 'darkgrey'),
                     name = 'Measure',
                     labels = c(expression("RT"[aud]~" [500 ms duration]  "),
                                expression("RT"[aud]~" [1000 ms duration]"),
                                expression("RT"[aud]~" [1500 ms duration]"),
                                expression("RT"[vis]~" [all durations]        "))) +
  scale_linetype_manual(values = c("solid", "longdash"),
                        name = 'SOA time-locked to',
                        breaks = c('onset', 'offset')) +
  theme_bw() +
  theme(axis.line = element_line(colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(linetype = "solid"),
        panel.background = element_blank(),
        axis.text = element_text(color = "black", size = 15),
        legend.text = element_text(size = 20),
        legend.title = element_text(size = 20, face="bold"),
        axis.title = element_text(size = 20, face="bold"),
        plot.title = element_text(size = 25, face="bold"),
        plot.tag = element_text(size = 25, face="bold"),
        strip.text = element_text(size = 20))

# plot figure
print(fig5a)

# specify the file name for the SVG and png export
svg_filename = "exp1_fig5a.svg"
png_filename = "exp1_fig5a.png"

# save an SVG and png graphic 
svg(svg_filename, width = width, height = height)
png(png_filename, width = width, height = height)

```

# plotting Figure 5b for experiment 1
- distribution analysis not preregistered

```{R plotting_fig5b_exp1}

# distribution analysis 

# define custom labels for the columns
custom_labels <- labeller(SOA_lock = c("onset" = "Onset", "offset" = "Offset"),
                          task_relevance = c("non-target" = "Relevant non-target",
                                             "irrelevant" = "Irrelevant non-target"),
                          duration = c("0.5" = "500 ms",
                                       "1" = "1000 ms",
                                       "1.5" = "1500 ms"))

# define order of task relevance
all_event_table$task_relevance <- factor(all_event_table$task_relevance, levels = c("non-target", "irrelevant"))

# plot for onset - split by task-relevance 
cdf_on = ggplot(all_event_table %>% filter(SOA_lock == 'onset'& z_RT_aud < 3), aes(x = z_RT_aud, color = as.factor(SOA))) +
  stat_ecdf(geom = "step", size = 1) +
  ylab("Cumulative Probability") +
  labs(title = "Auditory reaction time distribution", tag = "B") +
  #xlim(c(-2,3))+
  scale_color_manual(values = c('red', 'blue', '#00b300', "orange"), name = 'SOA [ms]', labels=c('0', '116', '232', '466'))+
  theme_bw() +
  theme(axis.line = element_line(colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(linetype = "solid"),
        panel.background = element_blank(),
        axis.text = element_text(color = "black", size = 15),
        legend.text = element_text(size = 20),
        legend.title = element_text(size = 20, face="bold"),
        axis.title = element_blank(),
        plot.title = element_text(size = 25, face="bold"),
        plot.tag = element_text(size = 25, face="bold"),
        strip.text = element_text(size = 20))+   
  facet_grid(SOA_lock ~ task_relevance, labeller = custom_labels)
cdf_on

# plot for offset - split by duration
cdf_off = ggplot(all_event_table %>% filter(SOA_lock == 'offset' & z_RT_aud < 3), aes(x = z_RT_aud, color = as.factor(SOA))) +
  stat_ecdf(geom = "step", size = 1) +
  ylab("Cumulative Probability") +
  xlab("z-scored auditory reaction time") +
#  xlim(c(-2,3))+
  scale_color_manual(values = c('red', 'blue', '#00b300', "orange"), name = 'SOA [ms]', labels=c('0', '116', '232', '466'))+
  theme_bw() +
  theme(axis.line = element_line(colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(linetype = "solid"),
        panel.background = element_blank(),
        axis.text = element_text(color = "black", size = 15),
        legend.text = element_text(size = 20),
        legend.title = element_text(size = 20, face="bold"),
        axis.title = element_text(size = 20, face="bold"),
        plot.title = element_text(size = 25, face="bold"),
        plot.tag = element_text(size = 25, face="bold"),
        strip.text = element_text(size = 20))+
  facet_grid(SOA_lock ~ duration, labeller = custom_labels)
cdf_off

# combine plots
fig5b = ggarrange(cdf_on, cdf_off, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right")
print(fig5b)

# specify the file name for the SVG and png export
svg_filename = "exp1_fig5b.svg"
png_filename = "exp1_fig5b.png"

# save an SVG and png graphic 
svg(svg_filename, width = width, height = height)
png(png_filename, width = width, height = height)

```

# main analysis experiment - model 1 

Generalized linear mixed effect model (GLMM)

fixed effects: SOA (ordinal), SOA-Lock (as c_is_onset,  numeric, centered), Task-relevance (as is relevant, numeric, centered)
random effects: Subject ID, Duration (ordinal)

```{r glmm1_epx1}

# single trial level (as preregistered)

# fit model
model1 = glmer(RT_aud ~ f_SOA*c_is_onset*c_task_relevant +
                     (1*f_SOA*c_is_onset*c_task_relevant | sub_id)+
                     (1*f_SOA*c_is_onset*c_task_relevant | f_duration),
               family=Gamma(link="identity"), data=all_event_table)

summary(model1)

# get chisquare and p values 
Anova(model1)

# residual plots for visual inspection
plot(fitted(model1),residuals(model1))
qqnorm(residuals(model1))

# get R square
rsq.glmm(model1)


# subject level model (mean of each cell for each subjects - no single trials) (not preregistered)

subj_data = all_event_table %>% group_by(f_SOA, c_is_onset, c_task_relevant, sub_id, f_duration) %>%
                                      summarise(RT_mean = mean(RT_aud, na.rm = TRUE))

sub_model1 = glmer(RT_mean ~ f_SOA*c_is_onset*c_task_relevant +
                     (1*f_SOA*c_is_onset*c_task_relevant | sub_id)+
                     (1*f_SOA*c_is_onset*c_task_relevant | f_duration),
               family=Gamma(link="identity"), data = subj_data)

summary(sub_model1)

# get chisquare and p values 
Anova(sub_model1)

# get R square
rsq.glmm(sub_model1)
```

# onset PRP analysis
- as preregistered

```{r onset_PRP1}

# sub analysis restricted to onset

onset_event_table = all_event_table %>% filter(SOA_lock == "onset")

# fit onset model 
onset_model = glmer(RT_aud ~ f_SOA*c_task_relevant +
                       (1*f_SOA*c_task_relevant | sub_id) + 
                      (1*f_SOA*c_task_relevant | f_duration), 
                     family = Gamma(link="identity"), data = onset_event_table)

summary(onset_model)

# get chisquare and p values 
Anova(onset_model)

# get R square
rsq.glmm(onset_model)

```

# offset PRP analysis
- as preregistered

```{r offset_PRP1}

# sub analysis restricted to offset

offset_event_table = all_event_table %>% filter(SOA_lock == "offset")

# fit offset model
offset_model = glmer(RT_aud ~ f_SOA*f_duration*c_task_relevant +
                       (1*f_SOA*f_duration*c_task_relevant | sub_id), 
                     family = Gamma(link="identity"), data = offset_event_table)

summary(offset_model)

# get chisquare and p values 
Anova(offset_model)

# get R square
rsq.glmm(offset_model)


# post-hoc bonferroni corrected pairwise comparison

em1 <- emmeans(offset_model, "f_SOA", by = "f_duration")
contrast(em1, "pairwise", adjust = "bonferroni")

```

# control model - model2
- as preregistered

```{r ctr_model2}


# with duration, category and pitch as random effects 

ctr_model = glmer(RT_aud ~ f_SOA*c_is_onset*c_task_relevant +
                     (1*f_SOA*c_is_onset*c_task_relevant | sub_id) +
                     (1*f_SOA*c_is_onset*c_task_relevant | f_duration) +
                     (1*f_SOA*c_is_onset*c_task_relevant | c_pitch) +
                     (1*f_SOA*c_is_onset*c_task_relevant | category), 
                   family=Gamma(link="identity"), data=all_event_table)


summary(ctr_model)

# get chisquare and p values 
Anova(ctr_model)

# get R square
rsq.glmm(ctr_model)

# compare control_model with main model
anova(model1, ctr_model)

```

# accuracy analysis - acc_model
GLMM with auditory accuracy as a dependent variable and SAO, onset/offset and task-relevance as fixed effects
- not preregistered

```{r acc_model1}

# make task relevance and SOA lock numeric
acc_event_table = raw_event_table %>% mutate(is_task_relevant = ifelse(task_relevance == 'non-target',1,0)) 
acc_event_table = acc_event_table %>% mutate(is_onset = ifelse(SOA_lock == 'onset',1,0))

# make SOA and duration factors 
acc_event_table = acc_event_table %>% mutate(f_SOA = factor(SOA, ordered = TRUE, levels = c("0", "0.116", "0.232", "0.466")))
acc_event_table = acc_event_table %>% mutate(f_duration = factor(duration, ordered = TRUE, levels = c("0.5", "1", "1.5")))

# center variables 
acc_event_table = acc_event_table %>% mutate(c_task_relevant = is_task_relevant - mean(is_task_relevant))
acc_event_table = acc_event_table %>% mutate(c_is_onset = is_onset - mean(is_onset))
acc_event_table = acc_event_table %>% mutate(c_SOA = SOA - mean(SOA))
acc_event_table = acc_event_table %>% mutate(c_duration = duration - mean(duration))
# remove targets 
acc_event_table = acc_event_table %>% filter(task_relevance != 'target')

acc_model = glmer(trial_accuracy_aud ~ f_SOA*c_is_onset*c_task_relevant +
                     (1*f_SOA*c_is_onset*c_task_relevant | sub_id)+
                     (1*f_SOA*c_is_onset*c_task_relevant | f_duration),
              family = binomial, data=acc_event_table)

summary(acc_model)
Anova(acc_model)


```

# accuracy analysis - accuracy plot (Figure S1) 
- not preregistered

```{r acc_plot}

# accuracy plot as RT plot
acc_data = raw_event_table %>% group_by(onset_SOA,SOA_lock, duration, sub_id, task_relevance) %>%
                                      summarise(acc_mean = mean(trial_accuracy_aud, na.rm = TRUE))

acc_data  = acc_data  %>%  group_by(onset_SOA, SOA_lock,duration, task_relevance) %>%
                                      summarise(mean_acc = mean(acc_mean, na.rm = TRUE),
                                                         sd_acc = sd(acc_mean, na.rm = TRUE),
                                                         sem_acc = sd_acc / sqrt(n))

# remove NaNs from auditory responses
acc_data  = acc_data [!is.na(acc_data $mean_acc), ]

# define order
acc_data $task_relevance = factor(acc_data $task_relevance,
                                   levels = c('target', 'non-target', 'irrelevant'),
                                   labels = c('Target', 'Relevant non-target', 'Irrelevant non-target'))


fig_S1 = ggplot(data = acc_data , aes(x = onset_SOA * 1000, y = mean_acc, group = interaction(as.character(duration), SOA_lock), color = as.character(duration), linetype = SOA_lock)) +
  geom_line(linewidth = 1) +
  geom_errorbar(aes(ymin = (mean_acc - sem_acc), ymax = (mean_acc + sem_acc)), width = 30, linewidth = 1) +
  geom_point(size = 1.5) +
  facet_grid(. ~ task_relevance) +
  labs(title = "Auditory accuracy by task-relevance") +
  ylab("Auditory accuracy [%]") +
  xlab('SOA to visual onset [ms]') +
  scale_color_manual(values = c('darkviolet', 'darkorange', 'darkred'),
                     name = 'Duration [ms]',
                     labels = c('500', '1000', '1500')) +
  scale_linetype_manual(values = c("solid", "longdash"),
                        name = 'SOA time-locked to',
                        breaks = c('onset', 'offset')) +
  theme_bw() +
  theme(axis.line = element_line(colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(linetype = "solid"),
        panel.background = element_blank(),
        axis.text = element_text(color = "black", size = 15),
        legend.text = element_text(size = 20),
        legend.title = element_text(size = 20, face="bold"),
        axis.title = element_text(size = 20, face="bold"),
        plot.title = element_text(size = 25, face="bold"),
        strip.text = element_text(size = 20))
fig_S1


```

# effect size of PRP

PRP effect magnitude: Difference in ms between short SOA and longest SOA for certain condition
PRP effect size: Cohen's D effect size for the same contrast

```{r effect size}

# initialize varibales
effect_size_table = matrix(ncol = 6, nrow = 5)
rownames(effect_size_table) = c("Mean_SOA0", "Mean_SOA466", "PRP_size", "joined_SD", "Cohensd")
colnames(effect_size_table) = c("target", "non_target_onset", "irrelevant_onset", "offset_short", "offset_intermediate", "offset_long")

# mean of SOA = 0
effect_size_table[1, ] = c(mean(target_event_table %>% filter(SOA == 0 & SOA_lock == 'onset' & task_relevance == 'target') %>% pull(RT_aud), na.rm = TRUE),
                           mean(target_event_table %>% filter(SOA == 0 & SOA_lock == 'onset' & task_relevance == 'non-target') %>% pull(RT_aud), na.rm = TRUE), 
                           mean(target_event_table %>% filter(SOA == 0 & SOA_lock == 'onset' & task_relevance == 'irrelevant') %>% pull(RT_aud), na.rm = TRUE), 
                           mean(all_event_table %>% filter(SOA == 0 & SOA_lock == 'offset' & duration == 0.5) %>% pull(RT_aud), na.rm = TRUE), 
                           mean(all_event_table %>% filter(SOA == 0 & SOA_lock == 'offset' & duration == 1) %>% pull(RT_aud), na.rm = TRUE), 
                           mean(all_event_table %>% filter(SOA == 0 & SOA_lock == 'offset' & duration == 1.5) %>% pull(RT_aud), na.rm = TRUE))

# mean of SOA = 466
effect_size_table[2, ] = c(mean(target_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' & task_relevance == 'target' & duration == 1.5) %>% pull(RT_aud), na.rm = TRUE),
                           mean(target_event_table %>% filter(SOA == 0.466 & SOA_lock == 'onset' & task_relevance == 'non-target') %>% pull(RT_aud), na.rm = TRUE),
                           mean(target_event_table %>% filter(SOA == 0.466 & SOA_lock == 'onset' & task_relevance == 'irrelevant') %>% pull(RT_aud), na.rm = TRUE),
                           mean(all_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' &  duration == 0.5) %>% pull(RT_aud), na.rm = TRUE),
                           mean(all_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' &  duration == 1) %>% pull(RT_aud), na.rm = TRUE),
                           mean(all_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' &  duration == 1.5) %>% pull(RT_aud), na.rm = TRUE))

# PRP size
effect_size_table[3, ] = effect_size_table[1, ] - effect_size_table[2, ] 

# joined SD
effect_size_table[4, ] = c(sd(c(target_event_table %>% filter(SOA == 0 & SOA_lock == 'onset' & task_relevance == 'target') %>% pull(RT_aud),target_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' & task_relevance == 'target' & duration == 1.5) %>% pull(RT_aud))),
                           sd(c(target_event_table %>% filter(SOA == 0 & SOA_lock == 'onset' & task_relevance == 'non-target') %>% pull(RT_aud), target_event_table %>% filter(SOA == 0.466 & SOA_lock == 'onset' & task_relevance == 'non-target') %>% pull(RT_aud))),
                           sd(c(target_event_table %>% filter(SOA == 0 & SOA_lock == 'onset' & task_relevance == 'irrelevant') %>% pull(RT_aud), target_event_table %>% filter(SOA == 0.466 & SOA_lock == 'onset' & task_relevance == 'irrelevant') %>% pull(RT_aud))),
                           sd(c(all_event_table %>% filter(SOA == 0 & SOA_lock == 'offset' & duration == 0.5) %>% pull(RT_aud), all_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' &  duration == 0.5) %>% pull(RT_aud))),
                           sd(c(all_event_table %>% filter(SOA == 0 & SOA_lock == 'offset' & duration == 1) %>% pull(RT_aud), all_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' &  duration == 1) %>% pull(RT_aud))),
                           sd(c(all_event_table %>% filter(SOA == 0 & SOA_lock == 'offset' & duration == 1.5) %>% pull(RT_aud), all_event_table %>% filter(SOA == 0.466 & SOA_lock == 'offset' &  duration == 1.5) %>% pull(RT_aud))))

# cohens d 
effect_size_table[5, ] = (effect_size_table[1, ] - effect_size_table[2, ])/effect_size_table[4, ]

```

# power analysis
Based on Marti el al. (2010). What is the minimum sample size required to find a PRP effect that is 4 times smaller than what Mart et al. have found with a power of 0.8?

```{r power_analysis}
if (!('pwr' %in% installed.packages()))
{install.packages("pwr")}
library(pwr)

# from marti paper
f =  47.08
n = 10
df_num = 5
df_denom = 45

# effect size 
eta = (f * df_num ) / (f * df_num  + df_denom )
effect_size = sqrt((df_denom/n)*(eta/(1-eta)))

# Specify  desired power, and significance level
power = 0.80
alpha = 0.05

# degrees of freedom for the numerator for our analysis 
u = 1

# Estimate sample size for GLMM with logistic regression
v = pwr.f2.test(u = u, v = , f2 = effect_size/4, sig.level = .05, power = power)$v
  
# (v = n - u - 1\). This implies \(n = v + u + 1\).
req_sample_size = ceiling(v + u + 1)

# show result
print(paste0("The required sample size is: ", req_sample_size))

```
